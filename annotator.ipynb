{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\umap\\distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\braes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\umap\\distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\braes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\umap\\distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\braes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\braes\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "from datasets import load_from_disk\n",
    "import re\n",
    "import csv\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from IPython.display import HTML\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text:\n",
    "def remove_links(text):\n",
    "    # Remove links starting with 'https' or 'http'\n",
    "    text_without_links = re.sub(r'https?\\S+', '', text)\n",
    "    return text_without_links\n",
    "\n",
    "def extract_text_from_csv(csv_file):\n",
    "    texts = []                                              # Create an empty list to store texts\n",
    "    ids = []                                                # Create an empty list to store tweet IDs\n",
    "    with open(csv_file, 'r', encoding='utf-8-sig') as file: # Open the CSV file in read mode\n",
    "        reader = csv.DictReader(file)                       # Create a CSV reader object\n",
    "        for row in reader:                                  # Iterate through each row in the CSV file\n",
    "            text = row['text']                              # Get the value of the 'text' column in the current row\n",
    "            id = row['tweet_id']                            # Get the value of the 'tweet_id' column in the current row\n",
    "            if text != '':                                  # Check if the text is not empty\n",
    "                cleaned = remove_links(text)                # Clean the text of links\n",
    "                texts.append(cleaned)                       # Add the text to the 'texts' list\n",
    "                ids.append(id)                              # Add the tweet ID to the 'ids' list\n",
    "    return texts, ids                                       # Return the 'texts' list and the 'ids' list as a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal: Load the pre-trained BERTopic model\n",
    "topic_model = BERTopic.load('NS_wildfire_2023~10,017(model)') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text: Load the pre-trained BERTopic model\n",
    "topic_model = BERTopic.load('ottawa_tornado_2018~10,009(text_model)') \n",
    "topics = topic_model.topics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal: Load the dataset\n",
    "loaded_dataset = load_from_disk('NS_wildfire_2023~10,017(dataset)')\n",
    "docs = loaded_dataset[\"text\"]\n",
    "images = loaded_dataset[\"image\"]\n",
    "topics = topic_model.topics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text: Load the dataset\n",
    "TEXTS, IDS = extract_text_from_csv('ottawa_tornado_2018~10,009.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal: print csv\n",
    "csv_file_name = 'NS_wildfire_2023~10,017(multimodal_processed).csv'\n",
    "useful_topics = [0,1,2,3,4,5,6,7,8,9,10,13,15,16,18,19,20,21,22,23,24,26,27,28,29,30,31,32]\n",
    "representations = topic_model.get_document_info(docs).get(\"Representation\")\n",
    "visual_aspects = topic_model.get_document_info(docs).get(\"Visual_Aspect\")\n",
    "data = [{'text': text, \n",
    "         'image': image, \n",
    "         #'Visual Aspect': va, \n",
    "         'topic_num': num, \n",
    "         'Representation': rep, \n",
    "         'possibly_useful': 'True' if num in useful_topics else None}\n",
    "          for text, image, va, num, rep in zip(docs, \n",
    "                                               images, \n",
    "                                               visual_aspects, \n",
    "                                               topics, \n",
    "                                               representations)]\n",
    "with open(csv_file_name, 'w', newline='', encoding='utf-8-sig') as csvfile:\n",
    "    fieldnames = ['text', \n",
    "                  'image', \n",
    "                  #'Visual Aspect', \n",
    "                  'topic_num', \n",
    "                  'Representation', \n",
    "                  'possibly_useful']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text: print csv\n",
    "csv_file_name = 'ottawa_tornado_2018~10,009(text_processed).csv'\n",
    "representations = topic_model.get_document_info(TEXTS).get(\"Representation\")\n",
    "useful_topics = [0,1,2,3,4,5,6,7,8,10,11,13,15,16,17,18,21,22,24,25,26,27,28,30,32]\n",
    "data = [{'text': text, \n",
    "         'topic_num': num, \n",
    "         'Representation': rep,\n",
    "         'possibly_useful': 'True' if num in useful_topics else None}\n",
    "          for text, num, rep in zip(TEXTS, topics, representations)]\n",
    "with open(csv_file_name, 'w', newline='', encoding='utf-8-sig') as csvfile:\n",
    "    fieldnames = ['text', \n",
    "                  'topic_num', \n",
    "                  'Representation',\n",
    "                  'possibly_useful']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labels.csv and output.csv files\n",
    "name = 'ottawa_tornado_2018~10,009(text_processed).csv'\n",
    "df1 = pd.read_csv('ottawa_tornado_text_labels.csv')\n",
    "df2 = pd.read_csv(name)\n",
    "\n",
    "# Merge the two dataframes based on 'topic_num'\n",
    "merged_df = pd.merge(df2, df1[['topic_num', 'label']], on='topic_num', how='left')\n",
    "\n",
    "# Rename the 'label' column to 'description'\n",
    "merged_df.rename(columns={'label': 'description'}, inplace=True)\n",
    "\n",
    "# Save the result back to 2.csv\n",
    "merged_df.to_csv(name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal:\n",
    "def get_thumbnail(image_path, size=(100, 100)):\n",
    "    try:\n",
    "        im = Image.open(image_path)\n",
    "        im.thumbnail(size)\n",
    "        return im\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating thumbnail: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def image_base64(im):\n",
    "    if isinstance(im, str):\n",
    "        im = get_thumbnail(im)\n",
    "    with BytesIO() as buffer:\n",
    "        im.save(buffer, 'jpeg')\n",
    "        return base64.b64encode(buffer.getvalue()).decode()\n",
    "\n",
    "def image_formatter(im):\n",
    "    return f'<img src=\"data:image/jpeg;base64,{image_base64(im)}\">'\n",
    "\n",
    "document_info = topic_model.get_document_info(docs).drop(\"Name\", 1).drop(\"Representative_Docs\", 1).drop(\"Top_n_words\", 1).drop(\"Representative_document\", 1)\n",
    "#document_info = document_info[:3]\n",
    "df = pd.DataFrame(document_info)\n",
    "# Visualize the images\n",
    "HTML(df.to_html(formatters={'Visual_Aspect': image_formatter}, escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.merge_topics(TEXTS, topics_to_merge=[37,6,65,10,39])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
